{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ati580_ml.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYoCjEtgxSMeceeJ1Qvzd4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uninstallit/ati580_final_project/blob/edvin-1/ati580_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRsRJpBpCyr3",
        "colab_type": "text"
      },
      "source": [
        "**Machine Learning portion of ATI580 Final Project**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXeaEC9UDlom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install dnspython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iFcX8e-rMux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install --upgrade tf-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPXcZjGOa-id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "pip freeze --local > /content/gdrive/My\\ Drive/colab_installed.txt\n",
        "\n",
        "# restore\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "pip install --upgrade --force-reinstall `cat/content/gdrive/My\\ Drive/colab_installed.txt`"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnUnpj-YbfmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plotly: https://plotly.com/python/ipython-notebook-tutorial/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "semGogYxCjNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "91dec066-3824-496c-8995-f246588b373e"
      },
      "source": [
        "import pymongo\n",
        "\n",
        "mdb_client = pymongo.MongoClient(\"mongodb+srv://mdbUser:ati580@ati580-cluster.s5t5z.gcp.mongodb.net/POLICE_DATABASE?retryWrites=true&w=majority\")\n",
        "mdb_database   = mdb_client['POLICE_DATABASE'] \n",
        "mdb_collection = mdb_database['POLICE_INTERVIEWS']\n",
        "mdb_collection.count_documents({})"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "593893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR3j6WP06CF1",
        "colab_type": "text"
      },
      "source": [
        "## **Structured data classification**\n",
        "- Data includes both numerical and categorical features. \n",
        "- Use Keras preprocessing layers to normalize the numerical features and vectorize the categorical ones.\n",
        "- Source: [Keras | Code examples](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/)\n",
        "- CategoricalEncoding API: [Tensorflow](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/experimental/preprocessing/CategoryEncoding#methods)\n",
        "\n",
        "## **Column Description**\n",
        "- SubjectGender   (Categorical)\n",
        "- SubjectAge.     (Numerical)\n",
        "- StopDescription (Categorical)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxvMtBdv8Vxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "35d42e6c-f1dc-47c6-de7a-0a25f7a9e8b5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# prepare the data \n",
        "cursor = mdb_collection.find({\n",
        "    \"$and\":[{\"SubjectGender\":{\"$exists\": True}}, \n",
        "            {\"SubjectGender\":{\"$ne\": \"\"}},\n",
        "            {\"SubjectGender\":{\"$ne\": None}},\n",
        "            {\"SubjectAge\":{\"$exists\": True}}, \n",
        "            {\"SubjectAge\":{\"$ne\": \"\"}},\n",
        "            {\"SubjectAge\":{\"$ne\": None}},\n",
        "            {\"StopDescription\":{\"$exists\": True}}, \n",
        "            {\"StopDescription\":{\"$ne\": \"\"}},\n",
        "            {\"StopDescription\":{\"$ne\": None}} ]}, \n",
        "            { \"_id\":0, \"SubjectGender\" : 1 , \"SubjectAge\" : 1 , \"StopDescription\" : 1})\n",
        "\n",
        "subject_df = pd.DataFrame(list(cursor))\n",
        "print(\"subject dataframe shape: {} \\n\".format(subject_df.shape))\n",
        "print(subject_df.head())\n",
        "\n",
        "reasonable_suspicion = {\"CALL FOR SERVICE\":1,\n",
        "                        \"CITIZEN CONTACT\":1,\n",
        "                        \"FLAGGED DOWN\":1,\n",
        "                        \"OTHER\":1,\n",
        "                        \"PRESENT AT CRIME SCENE\":1,\n",
        "                        \"SUSPECT PERSON\":1,\n",
        "                        \"SUSPECT VEHICLE\":1}\n",
        "\n",
        "probable_cause_list = {\"CRIMINAL VIOLATION\":0, \n",
        "                       \"JUVENILE VIOLATION\":0, \n",
        "                       \"TRAFFIC VIOLATION\":0}\n",
        "\n",
        "subject_df[\"StopDescription\"] = subject_df[\"StopDescription\"].replace(reasonable_suspicion)\n",
        "subject_df[\"StopDescription\"] = subject_df[\"StopDescription\"].replace(probable_cause_list)\n",
        "\n",
        "print(subject_df.head())\n",
        "\n",
        "# split the data into a training and validation set\n",
        "eval_subject_df  = subject_df.sample(frac=0.2, random_state=1337)\n",
        "train_subject_df = subject_df.drop(eval_subject_df.index)\n",
        "print(\"Using %d samples for training and %d for validation\" % (len(train_subject_df), len(eval_subject_df)))\n",
        "\n",
        "# convert dataframe_to_dataset \n",
        "def dataframe_to_dataset(dataframe, output_name):\n",
        "    _dataframe = dataframe.copy()\n",
        "    _labels    = _dataframe.pop(output_name)\n",
        "    _dataset   = tf.data.Dataset.from_tensor_slices((dict(_dataframe), _labels))\n",
        "    _dataset   = _dataset.shuffle(buffer_size=len(_dataframe))\n",
        "    return _dataset\n",
        "\n",
        "train_subject_ds = dataframe_to_dataset(train_subject_df, \"StopDescription\")\n",
        "eval_subject_ds  = dataframe_to_dataset(eval_subject_df, \"StopDescription\")\n",
        "\n",
        "train_subject_ds = train_subject_ds.batch(32)\n",
        "eval_subject_ds  = eval_subject_ds.batch(32)\n",
        "\n",
        "print(\"dataset preparation done\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "subject dataframe shape: (576132, 3) \n",
            "\n",
            "     StopDescription SubjectGender  SubjectAge\n",
            "0  TRAFFIC VIOLATION        FEMALE        26.0\n",
            "1   CALL FOR SERVICE          MALE        17.0\n",
            "2   CALL FOR SERVICE          MALE        18.0\n",
            "3   CALL FOR SERVICE          MALE        18.0\n",
            "4   CALL FOR SERVICE          MALE        30.0\n",
            "   StopDescription SubjectGender  SubjectAge\n",
            "0                0        FEMALE        26.0\n",
            "1                1          MALE        17.0\n",
            "2                1          MALE        18.0\n",
            "3                1          MALE        18.0\n",
            "4                1          MALE        30.0\n",
            "Using 460906 samples for training and 115226 for validation\n",
            "dataset preparation done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "estOeFNiezMH",
        "colab_type": "text"
      },
      "source": [
        "## **one-hot Encoding of features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKQ251LZeyi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
        "from tensorflow.keras.layers.experimental.preprocessing import CategoryEncoding\n",
        "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
        "\n",
        "\n",
        "def encode_numerical_feature(feature, name, dataset):\n",
        "    # Create a Normalization layer for our feature\n",
        "    normalizer = Normalization()\n",
        "    # Prepare a Dataset that only yields our feature\n",
        "    feature_ds = dataset.map(lambda x, y: x[name])\n",
        "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
        "    # Learn the statistics of the data\n",
        "    normalizer.adapt(feature_ds)\n",
        "    # Normalize the input feature\n",
        "    encoded_feature = normalizer(feature)\n",
        "    return encoded_feature\n",
        "\n",
        "def encode_string_categorical_feature(feature, name, dataset):\n",
        "    # Create a StringLookup layer which will turn strings into integer indices\n",
        "    index = StringLookup()\n",
        "    # Prepare a Dataset that only yields our feature\n",
        "    feature_ds = dataset.map(lambda x, y: x[name])\n",
        "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
        "    # Learn the set of possible string values and assign them a fixed integer index\n",
        "    index.adapt(feature_ds)\n",
        "    # Turn the string input into integer indices\n",
        "    encoded_feature = index(feature)\n",
        "    # Create a CategoryEncoding for our integer indices\n",
        "    encoder = CategoryEncoding(output_mode=\"binary\")\n",
        "    # Prepare a dataset of indices\n",
        "    feature_ds = feature_ds.map(index)\n",
        "    # Learn the space of possible indices\n",
        "    encoder.adapt(feature_ds)\n",
        "    # Apply one-hot encoding to our indices\n",
        "    encoded_feature = encoder(encoded_feature)\n",
        "    return encoded_feature\n",
        "\n",
        "def encode_integer_categorical_feature(feature, name, dataset):\n",
        "    # Create a CategoryEncoding for our integer indices\n",
        "    encoder = CategoryEncoding(output_mode=\"binary\")\n",
        "    # Prepare a Dataset that only yields our feature\n",
        "    feature_ds = dataset.map(lambda x, y: x[name])\n",
        "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
        "    # Learn the space of possible indices\n",
        "    encoder.adapt(feature_ds)\n",
        "    # Apply one-hot encoding to our indices\n",
        "    encoded_feature = encoder(feature)\n",
        "    return encoded_feature"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9OAOem0mAye",
        "colab_type": "text"
      },
      "source": [
        "## **Build the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC92GRZJmEUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Categorical features encoded as integers\n",
        "# stop_description = keras.Input(shape=(1,), name=\"StopDescription\", dtype=\"int64\")\n",
        "\n",
        "# Categorical feature encoded as string\n",
        "subject_gender = keras.Input(shape=(1,), name=\"SubjectGender\", dtype=\"string\")\n",
        "\n",
        "# Numerical features\n",
        "subject_age = keras.Input(shape=(1,), name=\"SubjectAge\")\n",
        "\n",
        "all_inputs = [subject_gender, subject_age]\n",
        "\n",
        "# Integer categorical features\n",
        "\n",
        "# String categorical features\n",
        "subject_gender_encoded = encode_string_categorical_feature(subject_gender, \"SubjectGender\", train_subject_ds)\n",
        "\n",
        "# Numerical features\n",
        "subject_age_encoded = encode_numerical_feature(subject_age, \"SubjectAge\", train_subject_ds)\n",
        "\n",
        "all_features = layers.concatenate([subject_gender_encoded, subject_age_encoded])\n",
        "\n",
        "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(all_inputs, output)\n",
        "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csyc_EpjSLb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "7c4bd3d0-2d04-4340-bfea-557b8be141f1"
      },
      "source": [
        "print(subject_gender.eval())\n",
        "# subject_gender_encoded"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f753f95e742d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_gender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# subject_gender_encoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \"\"\"\n\u001b[0;32m--> 914\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Use ref() instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5522\u001b[0m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5523\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5524\u001b[0;31m       raise ValueError(\"Cannot evaluate tensor using `eval()`: No default \"\n\u001b[0m\u001b[1;32m   5525\u001b[0m                        \u001b[0;34m\"session is registered. Use `with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5526\u001b[0m                        \u001b[0;34m\"sess.as_default()` or pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9BjVItnr9Gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# `rankdir='LR'` is to make the graph horizontal.\n",
        "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_geQsn5ssog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_subject_ds, epochs=50, validation_data=eval_subject_ds)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}