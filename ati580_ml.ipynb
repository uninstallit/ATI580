{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ati580_ml.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGRQmsCY6nyAUG0UWnRw6f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uninstallit/ati580_final_project/blob/edvin-1/ati580_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRsRJpBpCyr3",
        "colab_type": "text"
      },
      "source": [
        "**Machine Learning portion of ATI580 Final Project**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXeaEC9UDlom",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6c50042-d754-4439-abbd-f7bdcd460e60"
      },
      "source": [
        "pip install dnspython"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dnspython in /usr/local/lib/python3.6/dist-packages (1.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "semGogYxCjNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "877f574b-c4eb-41f5-b1e2-a8b3a0bab0fd"
      },
      "source": [
        "import pymongo\n",
        "\n",
        "mdb_client = pymongo.MongoClient(\"mongodb+srv://mdbUser:ati580@ati580-cluster.s5t5z.gcp.mongodb.net/POLICE_DATABASE?retryWrites=true&w=majority\")\n",
        "mdb_database   = mdb_client['POLICE_DATABASE'] \n",
        "mdb_collection = mdb_database['POLICE_INTERVIEWS']\n",
        "\n",
        "records = mdb_collection.find({})\n",
        "print(records[0].keys()) \n",
        "\n",
        "mdb_collection.count_documents({})"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['_id', 'FieldInterviewID', 'NOPD_Item', 'EventDate', 'District', 'Zone', 'OfficerAssignment', 'StopDescription', 'ActionsTaken', 'VehicleYear', 'VehicleMake', 'VehicleModel', 'VehicleStyle', 'VehicleColor', 'SubjectID', 'SubjectRace', 'SubjectGender', 'SubjectAge', 'SubjectHasPhotoID', 'SubjectHeight', 'SubjectWeight', 'SubjectEyeColor', 'SubjectHairColor', 'SubjectDriverLicState', 'CreatedDateTime', 'LastModifiedDateTime', 'Longitude', 'Latitude', 'Zip', 'BlockAddress'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "593893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2DDDhpwoYnz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "7a63c966-4a95-4d45-938d-ee07b6e9bc9a"
      },
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "test = mdb_collection.distinct('StopDescription')\n",
        "test_df = DataFrame(list(test))\n",
        "print(test_df)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test length:  10\n",
            "                        0\n",
            "0        CALL FOR SERVICE\n",
            "1         CITIZEN CONTACT\n",
            "2      CRIMINAL VIOLATION\n",
            "3            FLAGGED DOWN\n",
            "4      JUVENILE VIOLATION\n",
            "5                   OTHER\n",
            "6  PRESENT AT CRIME SCENE\n",
            "7          SUSPECT PERSON\n",
            "8         SUSPECT VEHICLE\n",
            "9       TRAFFIC VIOLATION\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR3j6WP06CF1",
        "colab_type": "text"
      },
      "source": [
        "## **Structured data classification**\n",
        "- Data includes both numerical and categorical features. \n",
        "- Use Keras preprocessing layers to normalize the numerical features and vectorize the categorical ones.\n",
        "- Source: [Keras | Code examples](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/)\n",
        "\n",
        "## **Column Description**\n",
        "- SubjectGender   (Categorical)\n",
        "- SubjectAge.     (Numerical)\n",
        "- StopDescription (Categorical)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxvMtBdv8Vxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "3647657d-f799-4fda-98c3-744c09be5609"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# prepare the data \n",
        "cursor = mdb_collection.find({\n",
        "    \"$and\":[{\"SubjectGender\":{\"$exists\": True}}, \n",
        "            {\"SubjectGender\":{\"$ne\": \"\"}},\n",
        "            {\"SubjectGender\":{\"$ne\": None}},\n",
        "            {\"SubjectAge\":{\"$exists\": True}}, \n",
        "            {\"SubjectAge\":{\"$ne\": \"\"}},\n",
        "            {\"SubjectAge\":{\"$ne\": None}},\n",
        "            {\"StopDescription\":{\"$exists\": True}}, \n",
        "            {\"StopDescription\":{\"$ne\": \"\"}},\n",
        "            {\"StopDescription\":{\"$ne\": None}} ]}, \n",
        "            { \"_id\":0, \"SubjectGender\" : 1 , \"SubjectAge\" : 1 , \"StopDescription\" : 1})\n",
        "\n",
        "subject_df = pd.DataFrame(list(cursor))\n",
        "print(\"subject dataframe shape: {} \\n\".format(subject_df.shape))\n",
        "print(subject_df.head())\n",
        "\n",
        "reasonable_suspicion = {\"CALL FOR SERVICE\":1,\n",
        "                        \"CITIZEN CONTACT\":1,\n",
        "                        \"FLAGGED DOWN\":1,\n",
        "                        \"OTHER\":1,\n",
        "                        \"PRESENT AT CRIME SCENE\":1,\n",
        "                        \"SUSPECT PERSON\":1,\n",
        "                        \"SUSPECT VEHICLE\":1}\n",
        "\n",
        "probable_cause_list = {\"CRIMINAL VIOLATION\":0, \n",
        "                       \"JUVENILE VIOLATION\":0, \n",
        "                       \"TRAFFIC VIOLATION\":0}\n",
        "\n",
        "subject_df[\"StopDescription\"] = subject_df[\"StopDescription\"].replace(reasonable_suspicion)\n",
        "subject_df[\"StopDescription\"] = subject_df[\"StopDescription\"].replace(probable_cause_list)\n",
        "\n",
        "print(subject_df.head())\n",
        "\n",
        "# split the data into a training and validation set\n",
        "eval_subject_df  = subject_df.sample(frac=0.2, random_state=1337)\n",
        "train_subject_df = subject_df.drop(eval_subject_df.index)\n",
        "print(\"Using %d samples for training and %d for validation\" % (len(train_subject_df), len(eval_subject_df)))\n",
        "\n",
        "# convert dataframe_to_dataset \n",
        "def dataframe_to_dataset(dataframe, output_col_name):\n",
        "    _dataframe = dataframe.copy()\n",
        "    _labels    = _dataframe.pop(output_col_name)\n",
        "    _dataset   = tf.data.Dataset.from_tensor_slices((dict(_dataframe), _labels))\n",
        "    _dataset   = _dataset.shuffle(buffer_size=len(_dataframe))\n",
        "    return _dataset\n",
        "\n",
        "train_subject_ds = dataframe_to_dataset(train_subject_df, \"StopDescription\")\n",
        "eval_subject_ds  = dataframe_to_dataset(eval_subject_df, \"StopDescription\")\n",
        "\n",
        "train_subject_ds = train_subject_ds.batch(32)\n",
        "eval_subject_ds  = eval_subject_ds.batch(32)\n",
        "\n",
        "print(\"dataset preparation done\")"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "subject dataframe shape: (576132, 3) \n",
            "\n",
            "     StopDescription SubjectGender  SubjectAge\n",
            "0  TRAFFIC VIOLATION        FEMALE        26.0\n",
            "1   CALL FOR SERVICE          MALE        17.0\n",
            "2   CALL FOR SERVICE          MALE        18.0\n",
            "3   CALL FOR SERVICE          MALE        18.0\n",
            "4   CALL FOR SERVICE          MALE        30.0\n",
            "   StopDescription SubjectGender  SubjectAge\n",
            "0                0        FEMALE        26.0\n",
            "1                1          MALE        17.0\n",
            "2                1          MALE        18.0\n",
            "3                1          MALE        18.0\n",
            "4                1          MALE        30.0\n",
            "Using 460906 samples for training and 115226 for validation\n",
            "dataset preparation done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}